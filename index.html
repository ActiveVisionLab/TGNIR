<html>

<head>
    <meta content='Towards Generalising Neural Implicit Representations' property='og:title' />
    <title>Towards Generalising Neural Implicit Representations</title>
    <link href='/images/fav.png' rel='shortcut icon'>
    <link href='http://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css' />
    <link href='/stylesheets/style.css' rel='stylesheet' type='text/css' />
    <link href='/stylesheets/syntax.css' rel='stylesheet' type='text/css' />
    <link href='/stylesheets/responsive.css' rel='stylesheet' type='text/css' />
    <!-- - -->
    <script src='/javascripts/jquery.js' type='text/javascript'></script>
    <script src='/javascripts/pd.js' type='text/javascript'></script>
    <script src='/javascripts/basics.js' type='text/javascript'></script>
    <script type="text/javascript" src="https://www.google.com/jsapi"></script>
    <!-- - -->
    <meta content='width=device-width, initial-scale=1.0, user-scalable=no' name='viewport'>
    <meta content='text/html; charset=utf-8' http-equiv='content-type' />
    <meta content="http://muan.co/images/og.png" property="og:image" />
    <meta content="" property="fb:app_id" />


</head>

<body>
    <div id='container'>
        <div class="block">

            <a target="_blank" class="main" href="https://code.active.vision"><strong>AVLCode</strong></a>

            <a target="_blank" class="main" href="https://github.com/ActiveVisionLab/GroSS"><strong>GitHub</strong></a>

        </div>

    </div>

    <header>
        <!-- <a id="go-back-home" href="index.html">
        <img id="myImage" src="images/main.png" alt="Teaser Image" width=700px />
    </a> -->
        <p style="font-size:200%; line-height: 120%">Towards Generalising Neural Implicit Representations
        </p>
    </header>

    <div id='container'>
        <div class="content">
            <p>This is the landing page for paper <strong>Towards Generalising Neural Implicit Representations</strong>.
            </p>

            <h2 id="abstract">Abstract</h2>
            <p>Neural implicit representations have shown substantial improvements in efficiently storing 3D data, when
                compared to conventional formats.
                However, the focus of existing work has mainly been on storage and subsequent reconstruction.
                In this work, we show that training neural representations for reconstruction tasks alongside
                conventional tasks can produce more general encodings that admit equal quality reconstructions to single
                task training, whilst improving results on conventional tasks when compared to single task encodings.
                We reformulate the semantic segmentation task, creating a more representative task for implicit
                representation contexts, and through multi-task experiments on reconstruction, classification, and
                segmentation, show our approach learns feature rich encodings that admit equal performance for each
                task.
                Further, through hold-out experiments, we show that adding semantic supervision when training implicit
                encoders can significantly improve performance on later unseen tasks, without requiring encoder
                retraining.
            </p>

            <p><strong>Code and paper to follow.</strong></p>

            <footer>
                <style>
                    div.column {
                        display: inline-block;
                        padding;
                        10px
                    }
                </style>
                <div class="row">
                    <div class="column">
                        <a href="http://www.ox.ac.uk/">
                            <img src="images/footer.png" height="40px" alt="logo" />
                        </a>
                    </div>
                </div>

            </footer>
</body>

</html>